{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas DataFrame\n",
    "- It is an equvivalant of excel of sql table in pandas\n",
    "- it is a collection of series\n",
    "- It has two axes row and column. row axes is denoted by 0 and column axes is denoted by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B    C\n",
      "0  1  10  100\n",
      "1  2  20  200\n",
      "2  3  30  300\n",
      "3  4  40  400\n",
      "date          1175\n",
      "dcoilwtico    1175\n",
      "dtype: int64\n",
      "good oil\n",
      "date          694\n",
      "dcoilwtico    694\n",
      "dtype: int64\n",
      "bad oil\n",
      "date          481\n",
      "dcoilwtico    481\n",
      "dtype: int64\n",
      "mean of good oil\n",
      "dcoilwtico    84.203487\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create a dataframe\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': [10, 20, 30, 40],\n",
    "    'C': [100, 200, 300, 400]\n",
    "})\n",
    "\n",
    "# print the dataframe\n",
    "print(df)\n",
    "\n",
    "# creating a dataframe by reading a csv file\n",
    "df = pd.read_csv('/Users/anand/learning/python/pylearn/notebooks/datascience/pandas/oil.csv',)\n",
    "# removing rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "df.shape\n",
    "# verifying that there is no missing value in the dataframe\n",
    "df.isna().sum()\n",
    "print(df.count())\n",
    "print(\"good oil\")\n",
    "good_oil = df.where(lambda x: x.dcoilwtico >= 50.0).dropna()\n",
    "print(good_oil.count())\n",
    "\n",
    "bad_oil = df.where(lambda x: x.dcoilwtico < 50.0).dropna()\n",
    "print(\"bad oil\")\n",
    "print(bad_oil.count())\n",
    "\n",
    "print(\"mean of good oil\")\n",
    "newDf = good_oil.drop(columns=['date'], axis=1)\n",
    "print(newDf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "properties of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1175, 2)\n",
      "columns: Index(['date', 'dcoilwtico'], dtype='object')\n",
      "index: Int64Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
      "            ...\n",
      "            1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217],\n",
      "           dtype='int64', length=1175)\n",
      "dtypes: date           object\n",
      "dcoilwtico    float64\n",
      "dtype: object\n",
      "axeses: [Int64Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
      "            ...\n",
      "            1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217],\n",
      "           dtype='int64', length=1175), Index(['date', 'dcoilwtico'], dtype='object')]\n",
      "Info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1175 entries, 1 to 1217\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        1175 non-null   object \n",
      " 1   dcoilwtico  1175 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 27.5+ KB\n",
      "None\n",
      "statistics about the data\n",
      "              date  dcoilwtico\n",
      "count         1175      1175.0\n",
      "unique        1175         NaN\n",
      "top     2013-01-02         NaN\n",
      "freq             1         NaN\n",
      "mean           NaN        68.0\n",
      "std            NaN        26.0\n",
      "min            NaN        26.0\n",
      "10%            NaN        42.0\n",
      "20%            NaN        45.0\n",
      "30%            NaN        48.0\n",
      "40%            NaN        50.0\n",
      "50%            NaN        53.0\n",
      "60%            NaN        77.0\n",
      "70%            NaN        94.0\n",
      "80%            NaN        97.0\n",
      "90%            NaN       103.0\n",
      "max            NaN       111.0\n"
     ]
    }
   ],
   "source": [
    "# properties of the dataframe\n",
    "print(f'shape: {df.shape}')\n",
    "print(f'columns: {df.columns}')\n",
    "print(f'index: {df.index}')\n",
    "print(f'dtypes: {df.dtypes}')\n",
    "print(f'axeses: {df.axes}')\n",
    "# print(\"First 2 rows\")\n",
    "# print(df.head(2))\n",
    "# print(\"Last 2 rows\")\n",
    "# print(df.tail(2))\n",
    "# print(\"random 2 samples\")\n",
    "# print(df.sample(2))\n",
    "print(\"Info\")\n",
    "print(df.info(show_counts=True))\n",
    "print(\"statistics about the data\")\n",
    "print(df.describe(percentiles=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], include='all').round())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store_nbr   city      state type  cluster\n",
      "0          1  Quito  Pichincha    D       13\n",
      "1          2  Quito  Pichincha    D       13\n",
      "   store_nbr  cluster\n",
      "0          1       13\n",
      "1          2       13\n",
      "   store_number City_name      state store_type  cluster\n",
      "0             1     Quito  Pichincha          D       13\n",
      "1             2     Quito  Pichincha          D       13\n",
      "   store_nbr   city      state store_type  cluster\n",
      "0          1  Quito  Pichincha          D       13\n",
      "1          2  Quito  Pichincha          D       13\n",
      "   store_nbr   city\n",
      "0          1  Quito\n",
      "1          2  Quito\n",
      "   store_nbr   city      state\n",
      "0          1  Quito  Pichincha\n",
      "1          2  Quito  Pichincha\n",
      "2          3  Quito  Pichincha\n",
      "   store_nbr   city  cluster\n",
      "0          1  Quito       13\n",
      "1          2  Quito       13\n",
      "(45, 3)\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "18    False\n",
      "19    False\n",
      "20    False\n",
      "21    False\n",
      "22    False\n",
      "23    False\n",
      "24    False\n",
      "25    False\n",
      "26    False\n",
      "27    False\n",
      "28    False\n",
      "29    False\n",
      "30    False\n",
      "31    False\n",
      "32    False\n",
      "33    False\n",
      "34    False\n",
      "35    False\n",
      "36    False\n",
      "37    False\n",
      "38    False\n",
      "39    False\n",
      "40    False\n",
      "41    False\n",
      "42    False\n",
      "43    False\n",
      "44    False\n",
      "45    False\n",
      "46    False\n",
      "47    False\n",
      "48    False\n",
      "49    False\n",
      "50    False\n",
      "51    False\n",
      "52    False\n",
      "53    False\n",
      "53     True\n",
      "dtype: bool\n",
      "(44, 3)\n",
      "store_nbr    44\n",
      "city         22\n",
      "cluster      16\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df columns can be accessed using the dot notation as well\n",
    "# column names should follow the python variable naming rules for the dot notation to work\n",
    "stores_df = pd.read_csv('/Users/anand/learning/python/pylearn/notebooks/datascience/pandas/stores.csv')\n",
    "print(stores_df.head(2))\n",
    "\n",
    "# you can also slice the df using the column names\n",
    "subStoresdf = stores_df[['store_nbr', 'cluster']].iloc[0:5]\n",
    "print(subStoresdf.head(2))\n",
    "\n",
    "# you can rename the columns by modifying the columns attribute\n",
    "stores_df.columns = ['store_number', 'City_name', 'state', 'store_type', 'cluster']\n",
    "print(stores_df.head(2))\n",
    "\n",
    "# you can also rename the columns using the rename method\n",
    "stores_df.rename(columns={'store_number': 'store_nbr', 'City_name': 'city'}, inplace=True)\n",
    "print(stores_df.head(2))\n",
    "\n",
    "# iloc for df\n",
    "# iloc is used to access the rows and columns by their integer index\n",
    "# iloc[row_index, column_index]\n",
    "# iloc is exclusive of the end index\n",
    "print(stores_df.iloc[0:2, 0:2])\n",
    "# loc is used to access the rows and columns by their labels\n",
    "# loc[row_label, column_label]\n",
    "# loc is inclusive of the end index\n",
    "print(stores_df.loc[0:2, 'store_nbr':'state'])\n",
    "\n",
    "# drop columns\n",
    "# drop columns using the drop method\n",
    "# drop method returns a new df with the columns dropped\n",
    "# to drop the columns in place, use the inplace parameter\n",
    "stores_df.drop(columns=['state', 'store_type'], inplace=True)\n",
    "print(stores_df.head(2))\n",
    "# droppping first 10 rows\n",
    "# generally rows are dropped using slicing\n",
    "stores_df.drop(range(10), axis= 0, inplace=True)\n",
    "# duplicate the last row\n",
    "stores_df = pd.concat([stores_df, stores_df.tail(1)])\n",
    "print(stores_df.shape)\n",
    "\n",
    "# the way to find duplicate rows is to use the duplicated method\n",
    "# this will return a boolean series\n",
    "# the first occurrence of the row is marked as False and the subsequent occurrences are marked as True\n",
    "# to get the duplicate rows, you can use the boolean series to filter the rows\n",
    "# this will return all the duplicate rows\n",
    "print(stores_df.duplicated())\n",
    "\n",
    "# identifying and dropping duplicate rows\n",
    "# duplicated method returns a boolean series\n",
    "# drop_duplicates method returns a new df with the duplicate rows removed\n",
    "# to drop the duplicates in place, use the inplace parameter\n",
    "# by default it remove the duplicates based on all the columns\n",
    "# to remove duplicates based on specific columns, use the subset parameter\n",
    "# this will remove the duplicates based on the store_nbr and city columns\n",
    "stores_df.drop_duplicates(subset=['store_nbr', 'city'],keep='last', inplace=True)\n",
    "print(stores_df.shape)\n",
    "\n",
    "# finding unique values\n",
    "# nunique method returns the number of unique values\n",
    "print(stores_df.nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering frame values\n",
    "# filtering the rows based on a condition\n",
    "# the condition should be a boolean series\n",
    "# Filtering a single row using loc function\n",
    "print(stores_df.head(2))\n",
    "print(stores_df.loc[stores_df.store_nbr == 11, ['store_nbr', 'city']]) # loc also takes a projection of columns\n",
    "# Filtering multiple rows using loc function\n",
    "print(stores_df.loc[stores_df.store_nbr.isin([11, 12]), ['store_nbr', 'city']])\n",
    "# Filtering the rows based on multiple conditions\n",
    "# the conditions should be combined using the bitwise operators\n",
    "# the conditions should be enclosed in parentheses\n",
    "cond = (stores_df.store_nbr == 11) | (stores_df.store_nbr == 12)\n",
    "print(stores_df.loc[cond, ['store_nbr', 'city']])\n",
    "\n",
    "# filter using where method\n",
    "# where method returns a new df with the rows that satisfy the condition\n",
    "# the rows that do not satisfy the condition are replaced with NaN\n",
    "# to drop the rows that do not satisfy the condition, use the dropna method\n",
    "print(stores_df.where(stores_df.store_nbr > 20).dropna().count())\n",
    "\n",
    "# sorting the data frame\n",
    "# sort_values method is used to sort the df\n",
    "# by default the sorting is done in ascending order\n",
    "stores_df.sort_values(by=['store_nbr'], ascending=False, inplace=True)\n",
    "\n",
    "# airthmatic column creation\n",
    "# you can create a new column by performing arithmetic operations on the existing columns\n",
    "stores_df['new_column'] = stores_df.store_nbr * 10\n",
    "\n",
    "# map method\n",
    "# a dict can be passed to the map method to create a new column\n",
    "# stores_df['new_column'] = stores_df.store_nbr.map({11: 110, 12: 120})\n",
    "stores_df['new_column'] = stores_df.store_nbr.map(lambda x: x * 100)\n",
    "\n",
    "# apply method\n",
    "stores_df['new_column'] = stores_df.apply(lambda x: x.store_nbr * 100, axis=1)\n",
    "print(stores_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catagorical data type\n",
    "- what is the difference between the categorical data type and the object data type?\n",
    "- the categorical data type is more memory efficient\n",
    "- the categorical data type is faster than the object data type for certain operations\n",
    "- It stores text data with repeating values as efficiently\n",
    "- python maps each unique cataegory to an integer to save space\n",
    "- As a rule of thumb only consider this data type when unique catagories < number of rows/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_nbr        int64\n",
      "city          category\n",
      "cluster          int64\n",
      "new_column       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "cat_df = stores_df.sort_values(by=['store_nbr'], ascending=False)\n",
    "\n",
    "# to convert a column to a categorical data type, use the astype method\n",
    "stores_df['city'] = stores_df['city'].astype('category')\n",
    "print(stores_df.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
